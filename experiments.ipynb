{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e984023-f43a-4c24-aa14-dff0f6a21594",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-10T13:15:15.672982Z",
     "iopub.status.busy": "2023-12-10T13:15:15.672308Z",
     "iopub.status.idle": "2023-12-10T13:15:18.574914Z",
     "shell.execute_reply": "2023-12-10T13:15:18.574103Z",
     "shell.execute_reply.started": "2023-12-10T13:15:15.672954Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "331d885a-c3b7-47a3-8655-92d0f0913fc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-10T14:35:39.309796Z",
     "iopub.status.busy": "2023-12-10T14:35:39.309388Z",
     "iopub.status.idle": "2023-12-10T14:35:41.242118Z",
     "shell.execute_reply": "2023-12-10T14:35:41.241281Z",
     "shell.execute_reply.started": "2023-12-10T14:35:39.309769Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch.encoders import get_preprocessing_fn\n",
    "# import albumentations as A\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "import mlflow\n",
    "\n",
    "# segmentation losses & metrics\n",
    "from utils import FocalLoss\n",
    "from utils import mIoULoss\n",
    "from utils import seg_acc as acc\n",
    "from utils import SegDataset, train\n",
    "\n",
    "os.environ['MLFLOW_TRACKING_USERNAME'] = 'Eighonet'\n",
    "os.environ['MLFLOW_TRACKING_PASSWORD'] = '507106c5c84dd39e349e6dbe8bf63f4aa36c2a0b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dd94761-d62c-4e31-bc0e-c9fed921475a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-10T14:07:41.243423Z",
     "iopub.status.busy": "2023-12-10T14:07:41.243044Z",
     "iopub.status.idle": "2023-12-10T14:07:43.245152Z",
     "shell.execute_reply": "2023-12-10T14:07:43.244335Z",
     "shell.execute_reply.started": "2023-12-10T14:07:41.243395Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Tesla T4\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = 'cpu'\n",
    "print(device)\n",
    "print(torch.cuda.get_device_name())\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c8699a-fe9b-440c-9740-e76434932c19",
   "metadata": {},
   "source": [
    "First of all, let us make this whole story truly reproducible (as it supposed to be everywhere in science)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04c5b371-8f4c-4b10-947b-6451309e522b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-10T14:07:43.247332Z",
     "iopub.status.busy": "2023-12-10T14:07:43.246690Z",
     "iopub.status.idle": "2023-12-10T14:07:43.283401Z",
     "shell.execute_reply": "2023-12-10T14:07:43.282852Z",
     "shell.execute_reply.started": "2023-12-10T14:07:43.247293Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def seed(value:int) -> None:\n",
    "    random.seed(value)\n",
    "    np.random.seed(value)\n",
    "    torch.manual_seed(value)\n",
    "\n",
    "seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61b798f-80d0-49f6-9bc6-1fae552eaf15",
   "metadata": {},
   "source": [
    "So, how we are going to make conclusions about observed metrics for various configurations of inputs, models, hyperparameters, etc.? In our case we will repeat training for the fixed (in some sense) configuration N times to obtain the metric sample. Following this idea, each model will have metric samples associated with them; further they can be compared by the Mann-Whitney U test indicating presence of statistical difference between them. \n",
    "\n",
    "About fixed configurations -- there are several possible approaches based on certain degrees of freedom:\n",
    "\n",
    "1. Train data can be fixed for each run in the sample or not.\n",
    "2. Seed value (which directly defines the initial weights of the model, optimizer, etc.) can be fixed for each run or not.\n",
    "\n",
    "In this notebook I am about to use the same data split but each model of the sample will be trained with its own seed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d1f187-5f69-4492-93e8-6b05c9dcbcab",
   "metadata": {},
   "source": [
    "### Augmentation & pre-training influence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fa040c-5757-4ef0-bf30-7b58bbeb3a1c",
   "metadata": {},
   "source": [
    "We will begin with something simple: naturally, the pre-training and relevant augmentations shoud have positive impact on the learning dynamics. Let's find out!\n",
    "\n",
    "Since our hypothesis is rather simple, it will be appropriate to test it on something with fast convergence (like the classic UNet architecture)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbc3a27e-aaf9-45e1-aa03-8fdb391e54e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-10T14:07:45.979641Z",
     "iopub.status.busy": "2023-12-10T14:07:45.979214Z",
     "iopub.status.idle": "2023-12-10T14:07:46.014970Z",
     "shell.execute_reply": "2023-12-10T14:07:46.014262Z",
     "shell.execute_reply.started": "2023-12-10T14:07:45.979612Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocess_input = get_preprocessing_fn('resnet34', pretrained='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e76fe85-4591-43dd-928b-6abf36164dd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-10T14:07:46.961715Z",
     "iopub.status.busy": "2023-12-10T14:07:46.961303Z",
     "iopub.status.idle": "2023-12-10T14:07:46.998881Z",
     "shell.execute_reply": "2023-12-10T14:07:46.998240Z",
     "shell.execute_reply.started": "2023-12-10T14:07:46.961688Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform_input = v2.Compose([\n",
    "#    v2.RandomCrop(128),\n",
    "#    v2.RandomHorizontalFlip(),\n",
    "#    v2.RandomRotation(degrees=(0, 180)),\n",
    "    get_preprocessing_fn('resnet34', pretrained='imagenet'),\n",
    "#color_shift = transforms.ColorJitter(.1,.1,.1,.1)\n",
    "#blurriness = transforms.GaussianBlur(3, sigma=(0.1, 2.0))\n",
    "    v2.ToTensor()\n",
    "])\n",
    "\n",
    "transform_mask = v2.Compose([\n",
    "    v2.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7150a6f6-e8ab-49e9-8aea-7a8a26344c71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-10T14:07:48.645502Z",
     "iopub.status.busy": "2023-12-10T14:07:48.645085Z",
     "iopub.status.idle": "2023-12-10T14:07:48.683511Z",
     "shell.execute_reply": "2023-12-10T14:07:48.682805Z",
     "shell.execute_reply.started": "2023-12-10T14:07:48.645472Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = SegDataset(inputs_path='processed_data/train/images/',\n",
    "                              targets_path='processed_data/train/masks/',\n",
    "                              transform_input=transform_input,\n",
    "                              transform_mask=transform_mask)\n",
    "\n",
    "val_dataset = SegDataset(inputs_path='processed_data/val/images/',\n",
    "                              targets_path='processed_data/val/masks/',\n",
    "                              transform_input=transform_input,\n",
    "                              transform_mask=transform_mask)\n",
    "\n",
    "test_dataset = SegDataset(inputs_path='processed_data/test/images/',\n",
    "                              targets_path='processed_data/test/masks/',\n",
    "                              transform_input=transform_input,\n",
    "                              transform_mask=transform_mask)\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                                      batch_size=4,\n",
    "                                      shuffle=True)\n",
    "\n",
    "val_dataloader = DataLoader(dataset=val_dataset,\n",
    "                                      batch_size=4,\n",
    "                                      shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_dataset,\n",
    "                                      batch_size=4,\n",
    "                                      shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f714a0-72b7-439f-a62b-ba1e403d8aab",
   "metadata": {},
   "source": [
    "There will be 3 models compared: random weights, pre-trained, pre-trained + augmented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "55910cd1-6294-4af6-8539-da6a9bafd82d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-10T14:35:55.490124Z",
     "iopub.status.busy": "2023-12-10T14:35:55.489730Z",
     "iopub.status.idle": "2023-12-10T14:35:55.526990Z",
     "shell.execute_reply": "2023-12-10T14:35:55.526252Z",
     "shell.execute_reply.started": "2023-12-10T14:35:55.490099Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 8\n",
    "N_EPOCHS = 30\n",
    "\n",
    "focal_criterion = FocalLoss(gamma=1.75).to(device)\n",
    "jaccard_criterion = mIoULoss(n_classes=2).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb35c0a4-e5f4-44cd-a402-eb09f4608352",
   "metadata": {},
   "source": [
    "#### Random vs pre-trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1abd73b7-f14d-4816-a64a-d97c06e74196",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-10T14:21:12.587301Z",
     "iopub.status.busy": "2023-12-10T14:21:12.586531Z",
     "iopub.status.idle": "2023-12-10T14:34:13.609722Z",
     "shell.execute_reply": "2023-12-10T14:34:13.608390Z",
     "shell.execute_reply.started": "2023-12-10T14:21:12.587268Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [03:01<03:50,  8.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lowering learning rate to 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [03:50<03:01,  8.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lowering learning rate to 2.5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [04:40<02:11,  8.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lowering learning rate to 1.25e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [05:29<01:22,  8.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lowering learning rate to 6.25e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [06:10<00:41,  8.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lowering learning rate to 3.125e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:03<00:00,  8.46s/it]\n",
      " 48%|████▊     | 24/50 [03:20<03:33,  8.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lowering learning rate to 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [04:09<02:44,  8.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lowering learning rate to 2.5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [04:58<01:55,  8.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lowering learning rate to 1.25e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [05:48<01:06,  8.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lowering learning rate to 6.25e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [05:55<01:07,  8.48s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m optimizer_r \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model_r\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m)\n\u001b[1;32m     12\u001b[0m lr_scheduler_r \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mStepLR(optimizer_r, step_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m best_r \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUNet_random_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msample_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m               \u001b[49m\u001b[43mmodel_r\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m               \u001b[49m\u001b[43moptimizer_r\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m               \u001b[49m\u001b[43mlr_scheduler_r\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m               \u001b[49m\u001b[43mfocal_criterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m               \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m               \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m               \u001b[49m\u001b[43mN_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m               \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m best_rs\u001b[38;5;241m.\u001b[39mappend(best_r)\n",
      "File \u001b[0;32m~/workspace/utils.py:183\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(run_name, model, optimizer, lr_scheduler, criterion, train_dataloader, val_dataloader, epochs, device)\u001b[0m\n\u001b[1;32m    181\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    182\u001b[0m jac_val, foc_val, acc_val, loss_val \u001b[38;5;241m=\u001b[39m [], [], [], []\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_i, (x, y, _, _) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(val_dataloader):\n\u001b[1;32m    185\u001b[0m     y \u001b[38;5;241m=\u001b[39m y[:, \u001b[38;5;241m0\u001b[39m, :]\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/workspace/utils.py:103\u001b[0m, in \u001b[0;36mSegDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    100\u001b[0m x, y \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mimread(input_ID), plt\u001b[38;5;241m.\u001b[39mimread(target_ID)\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_input \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 103\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    106\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_mask(y)\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.10/site-packages/torchvision/transforms/v2/_container.py:53\u001b[0m, in \u001b[0;36mCompose.forward\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m     51\u001b[0m needs_unpacking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(inputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 53\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m outputs \u001b[38;5;28;01mif\u001b[39;00m needs_unpacking \u001b[38;5;28;01melse\u001b[39;00m (outputs,)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.10/site-packages/segmentation_models_pytorch/encoders/_preprocessing.py:18\u001b[0m, in \u001b[0;36mpreprocess_input\u001b[0;34m(x, mean, std, input_space, input_range, **kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m-\u001b[39m mean\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m std \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 18\u001b[0m     std \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m/\u001b[39m std\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer_r = torch.optim.Adam(model_r.parameters(), lr=1e-4)\n",
    "best_rs = []\n",
    "for sample_id in range(SAMPLE_SIZE):\n",
    "    model_r = smp.Unet(\n",
    "        encoder_name=\"resnet34\",    \n",
    "        encoder_weights=None,     \n",
    "        in_channels=3,                  \n",
    "        classes=2,                      \n",
    "    ).to(device)\n",
    "    \n",
    "    optimizer_r = torch.optim.Adam(model_r.parameters(), lr=1e-4)\n",
    "    lr_scheduler_r = torch.optim.lr_scheduler.StepLR(optimizer_r, step_size=1, gamma=0.5)\n",
    "    \n",
    "    best_r = train(f'UNet_random_{sample_id}',\n",
    "                   model_r,\n",
    "                   optimizer_r,\n",
    "                   lr_scheduler_r,\n",
    "                   focal_criterion,\n",
    "                   train_dataloader,\n",
    "                   val_dataloader,\n",
    "                   N_EPOCHS,\n",
    "                   device)\n",
    "    best_rs.append(best_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642e0271-249f-4dbc-82ef-5b10fdfef025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e06d2e2-df55-4172-9bf1-b07ffa3c6fb4",
   "metadata": {},
   "source": [
    "1. What is the best (among the tested models) encoder-decoder for the selected task? Does it have a statistically significant difference regarding the other trained models?\n",
    "2. Does the pre-training has a statistically significant influence on the metric?\n",
    "\n",
    "Future work:\n",
    "\n",
    "**TBD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36b44f2-8127-4d89-afe1-dc520c0a801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation_models_pytorch.encoders import get_preprocessing_fn\n",
    "\n",
    "preprocess_input = get_preprocessing_fn('resnet34', pretrained='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5923bde4-d72e-4ff6-8678-0c48ca5c93b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cff5460-75ab-4afc-ae98-be6cf84abd4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
